{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- LIBRARIES -----\n",
    "from serpapi import GoogleSearch\n",
    "from urllib.parse import urlsplit, parse_qsl\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "#----- STATIC -----\n",
    "SERP_API_KEY = 'eff696b8dde4f4f2103c1534afb562364a2f4f8e1da2aabd9d88a212b025b543'\n",
    "SEARCH_QUERY = '(\"ability bias\" OR \"intelligence bias\") AND (\"private returns\") AND (\"income\" OR \"earnings\") AND (\"schooling\" OR \"education\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_search(start_from = 0):\n",
    "  '''Input a number of studies to skip when searching, and conduct the google scholar\n",
    "  search.\n",
    "  '''    \n",
    "  print(\"extracting organic results..\")\n",
    "\n",
    "  params = {\n",
    "    \"api_key\": SERP_API_KEY,            # https://serpapi.com/manage-api-key\n",
    "    \"engine\": \"google_scholar\",\n",
    "    \"q\": SEARCH_QUERY,  # search query\n",
    "    \"hl\": \"en\",        # language\n",
    "    # \"as_ylo\": \"2017\",  # from 2017\n",
    "    # \"as_yhi\": \"2021\",  # to 2021\n",
    "    \"start\": start_from\n",
    "  }\n",
    "\n",
    "  search = GoogleSearch(params)\n",
    "\n",
    "  return search\n",
    "\n",
    "def organic_results(search_results:list):\n",
    "  '''Input the google scholar search results, and transfrom them into a cool format.\n",
    "  '''\n",
    "  print(\"Extracting all organic data...\")\n",
    "  organic_results_data = []\n",
    "\n",
    "  for results in reversed(search_results): # Iterate over all 58 search results, each made up of results\n",
    "      try:\n",
    "        page_nr = results[\"search_information\"][\"page_number\"]\n",
    "      except KeyError: # The first page\n",
    "        page_nr = 1\n",
    "    \n",
    "      for result in results[\"organic_results\"]:\n",
    "          position = result[\"position\"]\n",
    "          title = result[\"title\"]\n",
    "          publication_info_summary = result[\"publication_info\"][\"summary\"]\n",
    "          result_id = result[\"result_id\"]\n",
    "          link = result.get(\"link\")\n",
    "          result_type = result.get(\"type\")\n",
    "          snippet = result.get(\"snippet\")\n",
    "      \n",
    "          try:\n",
    "            file_title = result[\"resources\"][0][\"title\"]\n",
    "          except: file_title = None\n",
    "      \n",
    "          try:\n",
    "            file_link = result[\"resources\"][0][\"link\"]\n",
    "          except: file_link = None\n",
    "      \n",
    "          try:\n",
    "            file_format = result[\"resources\"][0][\"file_format\"]\n",
    "          except: file_format = None\n",
    "      \n",
    "          try:\n",
    "            cited_by_count = int(result[\"inline_links\"][\"cited_by\"][\"total\"])\n",
    "          except: cited_by_count = None\n",
    "      \n",
    "          cited_by_id = result.get(\"inline_links\", {}).get(\"cited_by\", {}).get(\"cites_id\", {})\n",
    "          cited_by_link = result.get(\"inline_links\", {}).get(\"cited_by\", {}).get(\"link\", {})\n",
    "      \n",
    "          try:\n",
    "            total_versions = int(result[\"inline_links\"][\"versions\"][\"total\"])\n",
    "          except: total_versions = None\n",
    "      \n",
    "          all_versions_link = result.get(\"inline_links\", {}).get(\"versions\", {}).get(\"link\", {})\n",
    "          all_versions_id = result.get(\"inline_links\", {}).get(\"versions\", {}).get(\"cluster_id\", {})\n",
    "      \n",
    "          organic_results_data.append({\n",
    "            \"page_number\": page_nr,\n",
    "            \"position\": position + 1,\n",
    "            \"result_type\": result_type,\n",
    "            \"title\": title,\n",
    "            \"link\": link,\n",
    "            \"result_id\": result_id,\n",
    "            \"publication_info_summary\": publication_info_summary,\n",
    "            \"snippet\": snippet,\n",
    "            \"cited_by_count\": cited_by_count,\n",
    "            \"cited_by_link\": cited_by_link,\n",
    "            \"cited_by_id\": cited_by_id,\n",
    "            \"total_versions\": total_versions,\n",
    "            \"all_versions_link\": all_versions_link,\n",
    "            \"all_versions_id\": all_versions_id,\n",
    "            \"file_format\": file_format,\n",
    "            \"file_title\": file_title,\n",
    "            \"file_link\": file_link,\n",
    "          })\n",
    "\n",
    "  print(\"Extracted all organic data successfully.\")\n",
    "  return organic_results_data\n",
    "\n",
    "\n",
    "def cite_results(citation_df):\n",
    "  '''Input a pandas data frame including 3 columns - study title, link, and \n",
    "  the id. Return citations for those studyies.\n",
    "  '''    \n",
    "  print(\"extracting cite results..\")\n",
    "\n",
    "  citation_results = []\n",
    "\n",
    "  for row_iter in citation_df.iterrows():\n",
    "    row = row_iter[1]    \n",
    "    cite_title = row.title\n",
    "    cite_link = row.link\n",
    "    cite_id = row.result_id\n",
    "    try:\n",
    "      cite_id = cite_id.replace(\"\\\"\",\"\") # Remove extra double quotes, which are necessary in excel\n",
    "    except AttributeError:\n",
    "      citation_results.append({\n",
    "        \"organic_result_title\": cite_title,\n",
    "        \"organic_result_link\": cite_link,\n",
    "        \"citation_title\": cite_title,\n",
    "        \"citation_snippet\": \"FAILED_TO_RETRIEVE\"\n",
    "      })\n",
    "      continue\n",
    "\n",
    "    params = {\n",
    "      \"api_key\": SERP_API_KEY,\n",
    "      \"engine\": \"google_scholar_cite\",\n",
    "      \"q\": cite_id\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "\n",
    "    try:\n",
    "      result = results[\"citations\"][2] # Chicago citation\n",
    "\n",
    "      # Study citation and citation\n",
    "      cite_snippet = result[\"snippet\"]\n",
    "\n",
    "    except KeyError:\n",
    "      cite_snippet = \"FAILED_TO_RETRIEVE\"\n",
    "\n",
    "    citation_results.append({\n",
    "        \"organic_result_title\": cite_title,\n",
    "        \"organic_result_link\": cite_link,\n",
    "        \"citation_title\": cite_title,\n",
    "        \"citation_snippet\": cite_snippet\n",
    "    })\n",
    "\n",
    "  return citation_results\n",
    "\n",
    "def frame_to_csv(df, name):\n",
    "  '''Input the output data, and the name under which the csv file should be stored, and create said csv file.\n",
    "  '''    \n",
    "  pd.DataFrame(df).to_csv(f\"data/{name}.csv\", encoding=\"utf-8\", index=False)\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the jsons of the query searches from the scholar - one off-use, honestly\n",
    "search_ids = ['63d3f4d3f716eea2a73edb87', '63d3f4d01988e57397ea5f0c', '63d3f4cfd737d7f56356c6d3', '63d3f4ce7d171af45fc78ea4', '63d3f4cb3a218a3adefc640c', '63d3f4ca2c0844023a1870fc', '63d3f4c95fc493b2fc548b73', '63d3f4c89c84acc407de231a', '63d3f4c7c90e0a26f8d20d50', '63d3f4c649ecdb1c6b10a763', '63d3f4c4c47d3c991ca2ebda', '63d3f4c33a218a3b8819b3fd', '63d3f4c2303eb1d9579c8c93', '63d3f4c17f8361fec4fab5b5', '63d3f4be1988e5730214cf9c', '63d3f4bb11c88158ac7ce94d', '63d3f4bab7b1cc85416bed9e', '63d3f4b9ada54bb50bc2b725', '63d3f4b896f5d7dc33f3ef6d', '63d3f4b70b50621d23abb75e', '63d3f4b6d3aba21ff96af4b3', '63d3f4b4477c0efcad0ae3fe', '63d3f4b3e135084c19136ed5', '63d3f4b1d04d6ddb54964a56', '63d3f4b0f55d777a7a284e24', '63d3f4aff26ac6eb06ea1a41', '63d3f4ad979054b2fd2f092d', '63d3f4a7c47d3c988534c007', '63d3f4a6c56d933e01a0bbe8', '63d3f4a5c573d5ffd1461ea6', '63d3f4a458762b06b3bb1c69', '63d3f4a38ccee0dd1268a2a9', '63d3f4a294fb03609e53d68f', '63d3f4a1629a01b487a44b2c', '63d3f49f1988e57397ea5f0b', '63d3f49d7690dc9a4ac5710c', '63d3f49c8ccee0dda7b5a521', '63d3f49be815af0fe064b81d', '63d3f499ce87f85947b38fdb', '63d3f49896f5d7dc33f3ef65', '63d3f49249ecdb1bd018ee85', '63d3f490eb690f555c5845f6', '63d3f48f5119a69ae076d50e', '63d3f48a49ecdb1bd018ee84', '63d3f485ca968f407d20ffe5', '63d3f48379627c57bc8a522e', '63d3f481116a55631dc54f85', '63d3f480a1b42355d071be77', '63d3f47f9b647223b5f8e64a', '63d3f47eedb0343cedbe19b3', '63d3f47ddefa130f9325627b', '63d3f47cd04d6ddbee2af67f', '63d3f47bc504e907ea7c99ac', '63d3f47ad5ecf4552236a189', '63d3f478797ac6adbb1bf800', '63d3f477c7ad419a373b4c39', '63d3f4754d443d7812267e19', '63d3f47418ca86a7ab2cc077']\n",
    "all_data = []\n",
    "\n",
    "for id in search_ids:\n",
    "    url = f\"https://serpapi.com/searches/{id}?api_key={SERP_API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    all_data.append(data)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all organic data...\n",
      "Extracted all organic data successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hso20\\OneDrive\\Plocha\\IES\\Diploma-Thesis\\Tools and meta-analysis theory\\Scholar-bot\\.venv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:2323: RuntimeWarning: invalid value encountered in cast\n",
      "  values = values.astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Get the organic data of all the search results\n",
    "org_data = organic_results(all_data)\n",
    "frame_to_csv(org_data, \"org_data_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the excel file with clean, raw organic *(lol)* data, extract the result ids, and call the **SERPAPI** to get their citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the excel, extract onl the 3 necessary columns\n",
    "round = 3\n",
    "skip_rows = 100 * (round - 1)\n",
    "org_data_red = pd.read_excel('data/Query_data_clean.xlsx', sheet_name='raw_data')\n",
    "cit_df  = org_data_red[['title', 'link', 'result_id']]\n",
    "cit_df = cit_df[skip_rows:skip_rows+100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting cite results..\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m org_data \u001b[39m=\u001b[39m cite_results(cit_df) \u001b[39m# Query the actual google scholar for citations - takes away the search possibilities from the site\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[159], line 105\u001b[0m, in \u001b[0;36mcite_results\u001b[1;34m(citation_df)\u001b[0m\n\u001b[0;32m    103\u001b[0m cite_link \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mlink\n\u001b[0;32m    104\u001b[0m cite_id \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mresult_id\n\u001b[1;32m--> 105\u001b[0m cite_id \u001b[39m=\u001b[39m cite_id\u001b[39m.\u001b[39;49mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# Remove extra double quotes, which are necessary in excel\u001b[39;00m\n\u001b[0;32m    107\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m    108\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mapi_key\u001b[39m\u001b[39m\"\u001b[39m: SERP_API_KEY,\n\u001b[0;32m    109\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mgoogle_scholar_cite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    110\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m: cite_id\n\u001b[0;32m    111\u001b[0m }\n\u001b[0;32m    113\u001b[0m search \u001b[39m=\u001b[39m GoogleSearch(params)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "org_data = cite_results(cit_df) # Query the actual google scholar for citations - takes away the search possibilities from the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(org_data).to_csv(f\"data/citations{round}.csv\", index=False)\n",
    "pd.DataFrame(org_data).to_string(f\"data/citations{round}.txt\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc52d728104b1ea43e74abe1e947fc87d0af04bbe0084c4f899a3e33d8b4d627"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
