\chapter{Conclusion}
\label{conclusion}

In this thesis, I take a modern look at the relationship between education and earnings with the aim to discover whether and to what extent it is influenced by ability. From a large dataset of 154 studies, I colect 1754 estimates, and through a meticulous scrutiny of the latest meta-analytic research methods, I discover that ability bias is a significant factor in returns to schooling. Contrary to the conventional wisdom, which suggest returns of around 7\%, I propose that the true returns are significantly lower.

As a baseline, I report an average effect of returns to education around 7.4\%, which is very much inline with the previous literature. With this in mind, I run a battery of statistical tests that account for publication bias in the literature, I find that this baseline drops by roughly a full percentage point when publication bias is accounted for. I treat the data for endogeneity, which suggests an even lower effect (around 5.5\%), study structural breaks, and make use of the latest methodology including Elliot's p-hacking tests \citep{elliott2022hacking}, the MAIVE estimator \citep{irsova2023maive}, or the Robust Bayesian Model Averaging \citep{bartovs2023robust}. Although the results of some of the newer methods are mixed, the takeaway idea is that the returns to schooling are in general posioned by a small, but significant publication bias.

To see what role ability and other individual variables play in the picture (of which I collect more than 30), I make use of Bayesian Model Averaging. I find that ability is a highly important factor in determining one's future earnings, and that controlling for ability in the Mincer equation (\citep{mincer1974schooling}) has a significant negative impact on returns to education. Together with this finding, I identify a total of 19 variables that have a large impact on the returns to schooling, including the type of education one attains, their gender, ehtnicity, wage type, or the type of method used to estimate the returns. I run several different specifications of the model, including different model priors, g-priors, etc. to enhance the robustness of my findings.

Next, I calculate my subjective best-practice estimate, which I compare against the estimates of all individual studies in the dataset, as well as different subsets of these. Here, I mostly observe trends that are in line with the previous findings. To give a more deatiled picture of the results, I pool the best-practice estimates of each study into subsets by their study specifications, allowing me to single out effects of individual variables on returns to schooling. Further, I calculate the economic significance of every variable flagged as important during the Bayesian Model Averaging. These procedures, in general, agree with the results from the previous chapters. In other words, the notion persists that the studies whose authors control for ability, yield, on average, smaller coefficients of returns to education than their counterparts.

As the last, but not insignificant part of the analysis, I collect an entirely new dataset, comprised wholly of experiments whose subjects were identical twins (natural studies), in effort to observe the role of education on earnings in a setting where ability is assumed constant. I find that simply by limiting the pool of subjects to identical twins, the returns to education drop by a full percentage point. When controlling for publication bias, the returns drop even further, to an astonishing two to three percentage points difference.

All in all, I argue that once the data is clear of two important biases (ability and publication), the investment to schooling pays a considerably smaller interest, namely 4-6\% increase in log wage for an additional year spent in school, as opposed to the widely suggested 7\%. This is a crucial finding, as it suggests that the returns to schooling are not as high as previously thought, and that the role of ability in determining one's future earnings is more significant than previously assumed.

However, my approach in getting to these conclusions is not without its faults. Given the limited scope of the thesis, I opt to not to delve into the issues of measurement error and endogeneity when dealing with the natural experiments. The collected dataset provides enough resources to allow this kind of analysis, but perhaps another paper could be necessary to fit all of these results. Moreover, I find little time to focus on the implications of inidividual variables, both for the main dataset, and for the twins alike, although for an interested reader, they can be uncovered and scrutinized quite easily by replicating the analysis with the provided code.

As the last of my contributions, I would like to mention the existence of an open-source project I created along with this thesis that can be used to quickly and reliably replicate the whole analysis (see \href{https://github.com/PetrCala/Diploma-Thesis}{this link}). Further even, this project allows anyone with a completed meta-analysis dataset to automatically construct their own models, and export the results of these in a compact format that includes \textit{.csv} files, graphs, tables, console logs, and more. With the vast number of methods this tool utilizes, I opted to delve into the inner workings of several of them (including the STEM method by \cite{Furukawa2019Stem}, or the AK model by \cite{Bom2019Kink}), and either improved the speed of their code by a factor of up to 30x, or rewrote the whole methods to allow native execution in the R runtime. All of this creates a seemless user experience for anyone trying to conduct their own meta-analysis.

